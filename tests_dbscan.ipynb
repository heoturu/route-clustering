{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import fiona\n",
    "from itertools import chain\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from shapely.geometry import Point, Polygon, MultiPoint\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "import matplotlib.colors as mpl_colors\n",
    "from random import randint\n",
    "import time\n",
    "\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n",
      "Row done\n"
     ]
    }
   ],
   "source": [
    "threshold_dist_miles = 1.0\n",
    "\n",
    "with open('data_routes_pickle/routes_coord_f_any_3_closest_0.1', 'rb') as f:\n",
    "    routes_coord = pickle.load(f)\n",
    "\n",
    "coord_list = [[num for coords in route for num in coords] for route in routes_coord]\n",
    "\n",
    "def dist_vinc(pair):\n",
    "    return vincenty(pair[0], pair[1]).miles\n",
    "\n",
    "def similar_segments(segment1, segment2):\n",
    "    d_self_1 = dist_vinc((segment1[0], segment1[1]))\n",
    "    d_self_2 = dist_vinc((segment2[0], segment2[1]))\n",
    "\n",
    "    if d_self_1 < 0.001 or d_self_2 < 0.001:\n",
    "        return False\n",
    "\n",
    "    d1 = dist_vinc((segment1[0], segment2[0]))\n",
    "    d2 = dist_vinc((segment1[1], segment2[1]))\n",
    "\n",
    "    d3 = dist_vinc((segment1[0], segment2[1]))\n",
    "    d4 = dist_vinc((segment1[1], segment2[0]))\n",
    "\n",
    "    if ((d1 < threshold_dist_miles and d2 < threshold_dist_miles) or\n",
    "        (d3 < threshold_dist_miles and d4 < threshold_dist_miles)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def compute_distance(x, y, metric='l1'):\n",
    "    if metric == 'l1':\n",
    "        return np.linalg.norm((np.array(x) - np.array(y)), ord=1)\n",
    "    elif metric == 'sim_points':\n",
    "        points_x = list(zip(x[::2], x[1::2]))\n",
    "        points_y = list(zip(y[::2], y[1::2]))\n",
    "\n",
    "        total_common_count = 0\n",
    "        most_sim_points = min(product(points_x, points_y), key=dist_vinc)\n",
    "\n",
    "        while (vincenty(most_sim_points[0], most_sim_points[1]).miles < threshold_dist_miles and\n",
    "               len(points_x) > 1):\n",
    "            total_common_count += 1\n",
    "\n",
    "            points_x.remove(most_sim_points[0])\n",
    "            points_y.remove(most_sim_points[1])\n",
    "\n",
    "            most_sim_points = min(product(points_x, points_y), key=dist_vinc)\n",
    "\n",
    "        return 96 - total_common_count * 2\n",
    "    elif metric == 'sim_segments':\n",
    "        total_sim_segment_count = 0\n",
    "        for i in range(0, len(x) - 3, 2):\n",
    "            for j in range(0, len(y) - 3, 2):\n",
    "                if similar_segments(\n",
    "                    ((x[i], x[i + 1]), (x[i + 2], x[i + 3])),\n",
    "                    ((y[j], y[j + 1]), (y[j + 2], y[j + 3]))):\n",
    "                    total_sim_segment_count += 1.0 / 125.0 * abs(i - 48) * abs(j - 48)\n",
    "#         print(total_sim_segment_count)\n",
    "        return total_sim_segment_count\n",
    "\n",
    "    else:\n",
    "        raise Exception('Unknown metric')\n",
    "\n",
    "# number_of_paths = len(coord_list)\n",
    "number_of_paths = 100\n",
    "distance_matrix = np.zeros((number_of_paths, number_of_paths))\n",
    "for i in range(number_of_paths):\n",
    "    for j in range(i, number_of_paths):\n",
    "        if i == j:\n",
    "            distance = 0.0\n",
    "        else:\n",
    "            distance = compute_distance(coord_list[i], coord_list[j], 'sim_segments')\n",
    "        distance_matrix[i][j] = distance\n",
    "        distance_matrix[j][i] = distance\n",
    "#         print('Elem done')\n",
    "    print('Row done')\n",
    "\n",
    "with open('data_routes_pickle/sim_matrix_sim_segments_1', 'wb') as f:\n",
    "    pickle.dump(distance_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_matrix[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_matrix[12][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distance_matrix /= 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilon_range = np.arange(0.25, 1.55, 0.25) # y\n",
    "min_sample_range = np.arange(1, 10, 1) # x\n",
    "quality_matrix = np.zeros((len(epsilon_range), len(min_sample_range)))\n",
    "cluster_count_matrix = np.zeros((len(epsilon_range), len(min_sample_range)))\n",
    "\n",
    "# clustering_algorithm = DBSCAN(eps=0.5, min_samples=1, metric='precomputed')\n",
    "# labels = clustering_algorithm.fit_predict(distance_matrix)\n",
    "# sil = silhouette_score(np.array(coord_list[80:150]), labels)\n",
    "# print(labels)\n",
    "# print(sil)\n",
    "\n",
    "for min_sample_index, min_sample_size in enumerate(min_sample_range):\n",
    "    for eps_index, eps in enumerate(epsilon_range):\n",
    "#         clustering_algorithm = DBSCAN(eps=eps, min_samples=min_sample_size, metric='precomputed')\n",
    "        clustering_algorithm = KMeans(n_clusters=min_sample_size)\n",
    "        labels = clustering_algorithm.fit_predict(distance_matrix)\n",
    "        print(len(set(labels)))  # TODO Change endline symbol\n",
    "        cluster_count_matrix[eps_index][min_sample_index] = len(set(clustering_algorithm.labels_))\n",
    "        if 1 < len(set(clustering_algorithm.labels_)) < number_of_paths:\n",
    "            quality_matrix[eps_index][min_sample_index] = silhouette_score(np.array(coord_list[80:150]), labels)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(quality_matrix, interpolation='none', aspect=\"auto\",\n",
    "           extent=[np.min(min_sample_range), np.max(min_sample_range), np.max(epsilon_range), np.min(epsilon_range)])\n",
    "plt.clim(-1, 1)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.savefig(\"dbscan_output/dbscan {}.png\".format(int(time.time())), dpi=200, alpha=True)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(cluster_count_matrix, aspect=\"auto\", interpolation='none')\n",
    "# plt.clim(-1, 1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilon_range = np.arange(0.25, 1.55, 0.25) # y\n",
    "leaf_size_range = np.arange(1, 20, 2) # x\n",
    "quality_matrix = np.zeros((len(epsilon_range), len(leaf_size_range)))\n",
    "cluster_count_matrix = np.zeros((len(epsilon_range), len(leaf_size_range)))\n",
    "\n",
    "for leaf_size_index, leaf_size in enumerate(leaf_size_range):\n",
    "    for eps_index, eps in enumerate(epsilon_range):\n",
    "        clustering_algorithm = DBSCAN(eps=eps, min_samples=5, metric='precomputed')\n",
    "        labels = clustering_algorithm.fit_predict(distance_matrix)\n",
    "        cluster_count_matrix[eps_index][leaf_size_index] = len(set(clustering_algorithm.labels_))\n",
    "        if len(set(clustering_algorithm.labels_)) > 1:\n",
    "            quality_matrix[eps_index][leaf_size_index] = silhouette_score(np.array(coord_list), labels)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(quality_matrix, interpolation='none', aspect=\"auto\",\n",
    "           extent=[np.min(leaf_size_range), np.max(leaf_size_range), np.max(epsilon_range), np.min(epsilon_range)])\n",
    "plt.colorbar()\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(cluster_count_matrix, aspect=\"auto\", interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
