{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from itertools import chain\n",
    "from itertools import product\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "import fiona\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from shapely.geometry import Point, Polygon, MultiPoint\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "import matplotlib.colors as mpl_colors\n",
    "from random import randint\n",
    "import time\n",
    "\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold_dist_miles = 1.0\n",
    "\n",
    "with open('data_routes_pickle/routes_coord_f_any_3_closest_0.1_nocycles', 'rb') as f:\n",
    "    routes_coord = pickle.load(f)\n",
    "\n",
    "coord_list = routes_coord\n",
    "# coord_list = [[num for coords in route for num in coords] for route in routes_coord]\n",
    "\n",
    "def dist_vinc(pair):\n",
    "    return vincenty(pair[0], pair[1]).miles\n",
    "\n",
    "def similar_segments(segment1, segment2):\n",
    "    d1 = dist_vinc((segment1[0], segment2[0]))\n",
    "    d2 = dist_vinc((segment1[1], segment2[1]))\n",
    "\n",
    "    d3 = dist_vinc((segment1[0], segment2[1]))\n",
    "    d4 = dist_vinc((segment1[1], segment2[0]))\n",
    "\n",
    "    if (d1 < threshold_dist_miles and d2 < threshold_dist_miles or\n",
    "        d3 < threshold_dist_miles and d4 < threshold_dist_miles):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def similarity_rate(segment1, segment2): \n",
    "    d1 = dist_vinc((segment1[0], segment2[0]))\n",
    "    d2 = dist_vinc((segment1[1], segment2[1]))\n",
    "\n",
    "    d3 = dist_vinc((segment1[0], segment2[1]))\n",
    "    d4 = dist_vinc((segment1[1], segment2[0]))\n",
    "\n",
    "    return min(d1 + d2, d3 + d4)\n",
    "\n",
    "def compute_distance(route1, route2, metric='l1'):\n",
    "    if metric == 'l1':\n",
    "        return np.linalg.norm((np.array(route1) - np.array(route2)), ord=1)\n",
    "    elif metric == 'sim_points':\n",
    "        total_common_count = 0\n",
    "        route1_set = set(route1)\n",
    "        route2_set = set(route2)\n",
    "        \n",
    "        most_sim_points = min(product(route1_set, route2_set), key=dist_vinc)\n",
    "\n",
    "        while (vincenty(most_sim_points[0], most_sim_points[1]).miles < threshold_dist_miles and\n",
    "               min(len(route1_set), len(route2_set)) > 1):\n",
    "            total_common_count += 1\n",
    "\n",
    "            route1_set.remove(most_sim_points[0])\n",
    "            route2_set.remove(most_sim_points[1])\n",
    "\n",
    "            most_sim_points = min(product(route1_set, route2_set), key=dist_vinc)\n",
    "\n",
    "        return 48 - total_common_count\n",
    "    elif metric == 'sim_segments':\n",
    "        # Remove (only consecutive!) duplicates\n",
    "        route1_unique = list(map(itemgetter(0), groupby(route1)))\n",
    "        route2_unique = list(map(itemgetter(0), groupby(route2)))\n",
    "\n",
    "        total_sim_segment_count = 0\n",
    "        for i in range(len(route1_unique) - 1):\n",
    "            for j in range(len(route2_unique) - 1):\n",
    "                if similar_segments((route1_unique[i], route1_unique[i + 1]), \n",
    "                                    (route2_unique[j], route2_unique[j + 1])):\n",
    "                    total_sim_segment_count += 1.0 / 230.0 * abs(i - 48) * abs(j - 48)\n",
    "        return total_sim_segment_count\n",
    "    else:\n",
    "        raise Exception('Unknown metric')\n",
    "\n",
    "number_of_paths = len(coord_list)\n",
    "# number_of_paths = 100\n",
    "distance_matrix = np.zeros((number_of_paths, number_of_paths))\n",
    "for i in range(number_of_paths):\n",
    "    for j in range(i, number_of_paths):\n",
    "        if i == j:\n",
    "            distance = 0.0\n",
    "        else:\n",
    "            distance = compute_distance(coord_list[i], coord_list[j], 'sim_segments')\n",
    "        distance_matrix[i][j] = distance\n",
    "        distance_matrix[j][i] = distance\n",
    "#         print('Elem done')\n",
    "    print('Row done')\n",
    "\n",
    "with open('data_routes_pickle/sim_matrix_sim_segments_1', 'wb') as f:\n",
    "    pickle.dump(distance_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilon_range = np.arange(0.25, 1.55, 0.25) # y\n",
    "min_sample_range = np.arange(1, 10, 1) # x\n",
    "quality_matrix = np.zeros((len(epsilon_range), len(min_sample_range)))\n",
    "cluster_count_matrix = np.zeros((len(epsilon_range), len(min_sample_range)))\n",
    "\n",
    "# clustering_algorithm = DBSCAN(eps=0.5, min_samples=1, metric='precomputed')\n",
    "# labels = clustering_algorithm.fit_predict(distance_matrix)\n",
    "# sil = silhouette_score(np.array(coord_list[80:150]), labels)\n",
    "# print(labels)\n",
    "# print(sil)\n",
    "\n",
    "for min_sample_index, min_sample_size in enumerate(min_sample_range):\n",
    "    for eps_index, eps in enumerate(epsilon_range):\n",
    "#         clustering_algorithm = DBSCAN(eps=eps, min_samples=min_sample_size, metric='precomputed')\n",
    "        clustering_algorithm = KMeans(n_clusters=min_sample_size)\n",
    "        labels = clustering_algorithm.fit_predict(distance_matrix)\n",
    "        print(len(set(labels)))  # TODO Change endline symbol\n",
    "        cluster_count_matrix[eps_index][min_sample_index] = len(set(clustering_algorithm.labels_))\n",
    "        if 1 < len(set(clustering_algorithm.labels_)) < number_of_paths:\n",
    "            quality_matrix[eps_index][min_sample_index] = silhouette_score(np.array(coord_list[80:150]), labels)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(quality_matrix, interpolation='none', aspect=\"auto\",\n",
    "           extent=[np.min(min_sample_range), np.max(min_sample_range), np.max(epsilon_range), np.min(epsilon_range)])\n",
    "plt.clim(-1, 1)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.savefig(\"dbscan_output/dbscan {}.png\".format(int(time.time())), dpi=200, alpha=True)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(cluster_count_matrix, aspect=\"auto\", interpolation='none')\n",
    "# plt.clim(-1, 1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilon_range = np.arange(0.25, 1.55, 0.25) # y\n",
    "leaf_size_range = np.arange(1, 20, 2) # x\n",
    "quality_matrix = np.zeros((len(epsilon_range), len(leaf_size_range)))\n",
    "cluster_count_matrix = np.zeros((len(epsilon_range), len(leaf_size_range)))\n",
    "\n",
    "for leaf_size_index, leaf_size in enumerate(leaf_size_range):\n",
    "    for eps_index, eps in enumerate(epsilon_range):\n",
    "        clustering_algorithm = DBSCAN(eps=eps, min_samples=5, metric='precomputed')\n",
    "        labels = clustering_algorithm.fit_predict(distance_matrix)\n",
    "        cluster_count_matrix[eps_index][leaf_size_index] = len(set(clustering_algorithm.labels_))\n",
    "        if len(set(clustering_algorithm.labels_)) > 1:\n",
    "            quality_matrix[eps_index][leaf_size_index] = silhouette_score(np.array(coord_list), labels)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(quality_matrix, interpolation='none', aspect=\"auto\",\n",
    "           extent=[np.min(leaf_size_range), np.max(leaf_size_range), np.max(epsilon_range), np.min(epsilon_range)])\n",
    "plt.colorbar()\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.imshow(cluster_count_matrix, aspect=\"auto\", interpolation='none')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
